{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Inverse of a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import laUtilities as ut\n",
    "import slideUtilities as sl\n",
    "import demoUtilities as dm\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "reload(dm)\n",
    "reload(ut)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
       "    display: None ! important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_number": 3
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Today we investigate the idea of the \"reciprocal\" of a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 4
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For reasons that will become clear, we will think about this way:\n",
    "    \n",
    "The reciprocal of any nonzero number $r$ is its multiplicative inverse $1/r = r^{-1}$ such that $r \\cdot r^{-1} = 1.$\n",
    "\n",
    "This gives a way to define what is called the _inverse_ of a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 5
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we have to recognize that this inverse does not exist for all matrices.\n",
    "\n",
    "* It only exists for square matrices\n",
    "* And not even for all square matrices -- only those that are \"invertible.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 6
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Definition.__ A matrix $A$ is called __invertible__ if there exists a matrix $C$ such that\n",
    "\n",
    "$$ AC = I \\mbox{  and  } CA = I. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 7
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In that case $C$ is called the _inverse_ of $A$.   Clearly, $C$ must also be square and the same size as $A$.\n",
    "\n",
    "The inverse of $A$ is denoted $A^{-1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 8,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A matrix that is not invertible is called a __singular__ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 8,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example.__\n",
    "\n",
    "If $A = \\left[\\begin{array}{rr}2&5\\\\-3&-7\\end{array}\\right]$ and $C = \\left[\\begin{array}{rr}-7&-5\\\\3&2\\end{array}\\right]$, then:\n",
    "\n",
    "$$ AC = \\left[\\begin{array}{rr}2&5\\\\-3&-7\\end{array}\\right]\\left[\\begin{array}{rr}-7&-5\\\\3&2\\end{array}\\right] = \\left[\\begin{array}{rr}1&0\\\\0&1\\end{array}\\right],$$\n",
    "\n",
    "and:\n",
    "\n",
    "$$ CA = \\left[\\begin{array}{rr}-7&-5\\\\3&2\\end{array}\\right]\\left[\\begin{array}{rr}2&5\\\\-3&-7\\end{array}\\right] = \\left[\\begin{array}{rr}1&0\\\\0&1\\end{array}\\right],$$\n",
    "\n",
    "so we conclude that $C = A^{-1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 8,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's think about what a matrix inverse does in a linear equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 11
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have:\n",
    "\n",
    "$$ A{\\bf x} = {\\bf b}. $$\n",
    "\n",
    "So:\n",
    "\n",
    "$$A^{-1}(A{\\bf x}) = A^{-1}{\\bf b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 12
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$(A^{-1}A){\\bf x} = A^{-1}{\\bf b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 13
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$I{\\bf x} = A^{-1}{\\bf b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 14
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$${\\bf x} = A^{-1}{\\bf b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 15
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Theorem.__  If $A$ is an invertible $n\\times n$ matrix, the for each ${\\bf b}$ in $\\mathbb{R}^n,$ the equation $A{\\bf x} = {\\bf b}$ has the unique solution $A^{-1}{\\bf b}.$\n",
    "\n",
    "__Proof.__ Follows directly from the definition of $A^{-1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 16
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This very simple, powerful theorem gives us a new way to solve a linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 17,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Furthermore, this theorem connects the matrix inverse to certain kinds of linear systems.  \n",
    "\n",
    "We know that not all linear systems of $n$ equations in $n$ variables have a unique solution.  Such systems may have no solutions (inconsistent) or an infinite number of solutions.  \n",
    "\n",
    "But this theorem says that __if $A$ is invertible, then the system has a unique solution.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 17,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Matrix Inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 17
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Wonderful - so to solve a linear system, we simply need to compute the inverse of $A$ (if it exists).  \n",
    "\n",
    "How do we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 20
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Theorem.__  Let $A$ = $\\left[\\begin{array}{rr}a&b\\\\c&d\\end{array}\\right].$  If $ad-bc \\neq 0$, then $A$ is invertible and \n",
    "$$A^{-1} = \\frac{1}{ad-bc}\\left[\\begin{array}{rr}d&-b\\\\-c&a\\end{array}\\right].$$\n",
    "\n",
    "If $ad-bc = 0$, then $A$ is not invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 21
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that this theorem tells us, for $2\\times 2$ matrices, exactly _which ones_ are invertible: namely, those which have $ad-bc \\neq 0$.   This quantity is called the __determinant__ of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 22
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__  Given a $2\\times 2$ matrix $A$, if the columns of $A$ are linearly dependent, is $A$ invertible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 23
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__ If the columns of $A$ are linearly dependent, then at least one of the columns is a multiple of the other.  Let the multiplier be $m.$\n",
    "\n",
    "Then we can express $A$ as:\n",
    "$\\left[\\begin{array}{rr}a&ma\\\\b&mb\\end{array}\\right].$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 24,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The determinant of $A$ is $a(mb) - b(ma) = 0.$  \n",
    "\n",
    "So no $2\\times 2$ matrix with linearly dependent columns is invertible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 24,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Computing the inverse for matrices larger than $2\\times 2.$__\n",
    "\n",
    "Let's look at a general method for computing the inverse of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 26
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall our definition of matrix multiplication: $AB$ is the matrix formed by multiplying $A$ times each column of $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 27
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at the equation\n",
    "$$AA^{-1} = I.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 28
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's call the columns of $A^{-1}$ = $[{\\bf x_1}, {\\bf x_2}, \\dots, {\\bf x_n}].$  We know what the columns of $I$ are: $[{\\bf e_1}, {\\bf e_2}, \\dots, {\\bf e_n}].$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 29
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So: \n",
    "\n",
    "$$ AA^{-1} = A[{\\bf x_1}, {\\bf x_2}, \\dots, {\\bf x_n}] = [{\\bf e_1}, {\\bf e_2}, \\dots, {\\bf e_n}].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 30
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So here is a general way to compute the inverse of $A$:\n",
    "\n",
    "* Solve the linear system $A{\\bf x_1} = {\\bf e_1}$ to get the first column of $A^{-1}.$\n",
    "* Solve the linear system $A{\\bf x_2} = {\\bf e_2}$ to get the second column of $A^{-1}.$\n",
    "* $\\dots$\n",
    "* Solve the linear system $A{\\bf x_n} = {\\bf e_n}$ to get the last column of $A^{-1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 31,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If any of the systems are inconsistent or have an infinite solution set, then $A^{-1}$ does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 31,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__The Computational View.__\n",
    "\n",
    "This general strategy leads to an algorithm, described in the book, for inverting any matrix.  However, in this course I will not ask you invert matrices larger than $2\\times 2$ by hand.  Any time you need to invert a matrix larger than $2\\times 2,$ you may use a calculator or computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 33
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To invert a matrix in `Python/numpy,` use the function `np.linalg.inv().`  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 34
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      "[[ 2.  5.]\n",
      " [-3. -7.]]\n",
      "B = \n",
      "[[-7. -5.]\n",
      " [ 3.  2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[2.0,5.0],[-3.0,-7.0]])\n",
    "print 'A ='; print A\n",
    "B = np.linalg.inv(A)\n",
    "print 'B = '; print B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 35
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do you think happens if you call `np.linalg.inv()` on a matrix that is not invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 36
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-27af7ae5865c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/markcrovella/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markcrovella/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "A = np.array([[2.,4.],[2.,4.]])\n",
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 37
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The right way to handle this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 37,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([[2.,4.],[2.,4.]])\n",
    "try:\n",
    "    np.linalg.inv(A)\n",
    "except np.linalg.LinAlgError:\n",
    "    print 'Oops, looks like A is singular!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 37,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Using the matrix inverse to solve a linear system.__\n",
    "\n",
    "Solve the system:\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "3x_1 +4x_2 &=& 3\\\\\n",
    "5x_1 +6x_2 &=& 7\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 40
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rewrite this system as $A{\\bf x} = {\\bf b}:$\n",
    "\n",
    "$$ \\left[\\begin{array}{rr}3&4\\\\5&6\\end{array}\\right] {\\bf x} = \\left[\\begin{array}{r}3\\\\7\\end{array}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 41
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The determinant of $A$ is $3(6)-4(5) = -2,$ which is nonzero, so $A$ has an inverse. The inverse of $A$ is:\n",
    "\n",
    "$$ A^{-1} = \\frac{1}{-2}\\left[\\begin{array}{rr}6&-4\\\\-5&3\\end{array}\\right] = \\left[\\begin{array}{rr}-3&2\\\\5/2&-3/2\\end{array}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 42,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the solution is:\n",
    "\n",
    "$$ {\\bf x} = A^{-1}{\\bf b} = \\left[\\begin{array}{rr}-3&2\\\\5/2&-3/2\\end{array}\\right]\\left[\\begin{array}{r}3\\\\7\\end{array}\\right] = \\left[\\begin{array}{r}5\\\\-3\\end{array}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 42,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Theorem.__\n",
    "\n",
    "* If $A$ is an invertible matrix, then $A^{-1}$ is invertible, and\n",
    "$$(A^{-1})^{-1} = A.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 44
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $A$ is an invertible matrix, then so is $A^T,$ and the inverse of $A^T$ is the transpose of $A^{-1}.$\n",
    "$$(A^T)^{-1} = (A^{-1})^T.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 45
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If $A$ and $B$ are $n\\times n$ invertible matrices, then so is $AB,$ and the inverse of $AB$ is the product of the inverses of $A$ and $B$ in the reverse order.  \n",
    "$$(AB)^{-1} = B^{-1}A^{-1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 46
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first two are straightforward.  Let's verify the last one because it shows some common calculation patterns:\n",
    "$$(AB)(B^{-1}A^{-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 47
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=A(BB^{-1})A^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 48
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=AIA^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 49
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=AA^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 50,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=I.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 50,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Invertible Matrix Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 50
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Earlier we saw that if a matrix $A$ is invertible, then $A{\\bf x} = {\\bf b}$ has a unique solution for any ${\\bf b}$.\n",
    "\n",
    "This suggests a deep connection between the invertibility of $A$ and the linear system $A{\\bf x} = {\\bf b}.$\n",
    "\n",
    "In fact, we are now at the point where we can collect together in a fairly complete way much of what we have learned about matrices and linear systems.   This remarkable collection of ten interrelated properties is called the __Invertible Matrix Theorem (IMT).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 53
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Invertible Matrix Theorem.__  Let $A$ by a square $n\\times n$ matrix.  Then the following statements are equivalent; that is, they are either __all true__ or __all false__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 54
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $A$ is an invertible matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 55
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $A^T$ is an invertible matrix.\n",
    "    * Proof by direct construction: $(A^T)^{-1} = (A^{-1})^T.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 56
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The equation $A{\\bf x} = {\\bf b}$ has a unique solution for each ${\\bf b}$ in $\\mathbb{R}^n.$\n",
    "    * As already mentioned, we proved this above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 57
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A is row equivalent to the identity matrix.\n",
    "    * If $A{\\bf x} = {\\bf b}$ has a unique solution for any ${\\bf b},$ then the reduced row echelon form of $A$ is $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 58
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A has $n$ pivot positions.\n",
    "    * Follows directly from the previous statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 59
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The equation $A{\\bf x} = {\\bf 0}$ has only the trivial solution.\n",
    "    * If $A{\\bf x} = {\\bf b}$ has a unique solution for any ${\\bf b},$ then the unique solution for ${\\bf b} = {\\bf 0}$ must be ${\\bf 0.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 60
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The columns of $A$ form a linearly independent set.\n",
    "    * Follows directly the previous statement and the definition of linear independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 61
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The columns of $A$ span $\\mathbb{R}^n.$\n",
    "    * For any ${\\bf b} \\in \\mathbb{R}^n,$ there is a set of coefficients ${\\bf x}$ which can be used to construct ${\\bf b}$ from the columns of $A.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 62
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The linear transformation ${\\bf x} \\mapsto A{\\bf x}$ maps $\\mathbb{R}^n$ onto $\\mathbb{R}^n.$\n",
    "    * \"maps onto\" means that every element in the codomain is in the range.\n",
    "    * Follows directly from the previous statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 63
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The linear transformation ${\\bf x} \\mapsto A{\\bf x}$ is one-to-one.\n",
    "    * \"one-to-one\" means that there is a unique ${\\bf x}$ for each $A{\\bf x}.$\n",
    "    * Follows directly from the fact that $A{\\bf x} = {\\bf b}$ has a unique solution for any ${\\bf b}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 64
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The arguments above show that if $A$ is invertible, then all the other statements are true.  In fact, the converse holds as well: if $A$ is not invertible, then all the other statements are false.  (We will skip the proof of the converse, but it's not difficult.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 65
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This theorem has wide-ranging implications.  It divides the set of all $n\\times n$ matrices into two disjoint classes: the invertible (nonsingular) matrices, and the noninvertible (singular) matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 66
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The power of the IMT lies in the conections it provides among so many important concepts, such as linear idenpendence of the columns of a matrix $A$ and the existence of solutions to equations of the form $A{\\bf x} = {\\bf b}.$\n",
    "\n",
    "This allows us to bring many tools to bear as needed to solve a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 67
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__  Decide if $A$ is invertible:\n",
    "\n",
    "$$A = \\left[\\begin{array}{rrr}1&0&-2\\\\3&1&-2\\\\-5&-1&9\\end{array}\\right].$$\n",
    "\n",
    "__Solution.__\n",
    "\n",
    "$$A \\sim \\left[\\begin{array}{rrr}1&0&-2\\\\0&1&4\\\\0&-1&-1\\end{array}\\right] \\sim \\left[\\begin{array}{rrr}1&0&-2\\\\0&1&4\\\\0&0&3\\end{array}\\right].$$\n",
    "\n",
    "So $A$ has three pivot positions and hence is invertible, by the IMT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 68,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Note.__ While the IMT is quite powerful, it does not completely settle issues that arise with respect to $A{\\bf x} = {\\bf b}.$  This is because __it only applies to square matrices.__\n",
    "\n",
    "So if $A$ is nonsquare, then we can't use the IMT to conclude anything about the existence or nonexistence of solutions to $A{\\bf x} = {\\bf b}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 68,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Invertible Linear Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 68
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# image credit: Scan from Lay, 4th edition\n",
    "sl.hide_code_in_slideshow()\n",
    "display(Image(\"images/Lay-fig-2-3-2.jpeg\", width=450))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 71
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A linear transformation $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ is __invertible__ if there exists a function $S: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ such that\n",
    "$$ S(T({\\bf x})) = {\\bf x}\\;\\;\\;\\mbox{for all}\\;{\\bf x}\\in\\mathbb{R}^n,$$\n",
    "and\n",
    "$$ T(S({\\bf x})) = {\\bf x}\\;\\;\\;\\mbox{for all}\\;{\\bf x}\\in\\mathbb{R}^n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 72,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Theorem.__ Let $T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ be a linear transformation and let $A$ be the standard matrix for $T$.  Then $T$ is invertible if and only if $A$ is an invertible matrix.  In that case the linear transformation $S$ given by $S({\\bf x}) = A^{-1}{\\bf x}$ is the unique function satisfying the definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 72,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at some invertible and non-invertible linear transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 74
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "square = np.array([[0.0,1,1,0],[1,1,0,0]])\n",
    "A = np.array([[0.5,0],[0,1]])\n",
    "print A\n",
    "ax = dm.plotSetup(-3,3,-3,3)\n",
    "dm.plotSquare(square)\n",
    "dm.plotSquare(A.dot(square),'r')\n",
    "Latex(r'Horizontal Contraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 75
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here $A = \\left[\\begin{array}{rr}0.5&0\\\\0&1\\end{array}\\right].$  Its determinant is $1(0.5)-0(0) = 0.5,$ so this linear transformation is invertible.\n",
    "\n",
    "Its inverse is:\n",
    "$$ \\frac{1}{0.5}\\left[\\begin{array}{rr}1&0\\\\0&0.5\\end{array}\\right] = \\left[\\begin{array}{rr}2&0\\\\0&1\\end{array}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 76,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Clearly, just as $A$ contracted the $x_1$ direction by 0.5, $A^{-1}$ will expand the $x_1$ direction by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 76,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([[0,0],[0,1]])\n",
    "print A\n",
    "ax = dm.plotSetup(-3,3,-3,3)\n",
    "dm.plotSquare(A.dot(square))\n",
    "Latex(r'Projection onto the $x_2$ axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 78
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here $A = \\left[\\begin{array}{rr}0&0\\\\0&1\\end{array}\\right].$  Its determinant is zero, so this linear transformation is __not__ invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 79,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By the IMT, there are many equivalent ways to look at this:\n",
    "\n",
    "* The mapping $T$ is not from $\\mathbb{R}^2$ to $\\mathbb{R}^2.$\n",
    "* There are many values ${\\bf x}$ that give the same $A{\\bf x}.$\n",
    "* $A$ does not have 2 pivots.\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 79,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ill-Conditioned Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 81
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notion of a matrix inverse has some complications when used in practice.  \n",
    "\n",
    "As we've noted, numerical computations are not exact, and in particular, we often find that `a - b(a/b)` does not evaluate to exactly zero on a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 82
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For similar reasons, a matrix which is actually singular may not appear to be so when used in a computation.  \n",
    "\n",
    "Conversely, a matrix which is not singular may appear to be singular when used in a computation.  This happens because, for example, the determinant does not evaluate to exactly zero, even though it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 83
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You recall that when we were implementing Gaussian elimination, we established a rule that if `a - b(a/b) < epsilon` for some `epsilon`, we would treat that quantity as if it were zero.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 84
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need an equivalent rule for matrices, so that we recognize when matrices are \"nearly singular,\" and we don't try to solve $A{\\bf x} = {\\bf b}$ when that is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 85
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This value is called the __condition number.__  The larger the condition number, the closer the matrix is to being singular.   \n",
    "\n",
    "The condition number of the identity matrix is 1, which is the smallest possible value.  A singular matrix has an infinite condition number.\n",
    "\n",
    "The point is that a matrix with a very large condition number, say, bigger than $10^8,$ will behave much like a singular matrix in practice.  \n",
    "\n",
    "One should not try to solve linear systems by computer when the matrix $A$ has a very large condition number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 86
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Analogy.__\n",
    "\n",
    "First, here is an analogy.\n",
    "\n",
    "If a number is small, we might say that it is \"almost zero.\"    \n",
    "\n",
    "A very small number can behave almost like zero in some situations.   Consider a very small number like 0.0000000000001.   Now add it to 1.  The result is very close to 1 -- which is what you would have gotten if the number had been zero.   Of course the result is not exactly 1 -- but if you are working on a computer, with limited precision, you might get exactly 1 by accident.\n",
    "\n",
    "If a matrix has a large condition number, we might say that it is \"almost singular.\"\n",
    "\n",
    "A matrix that has a large condition number can behave almost like it is singular.   We know that if $A$ is a singular matrix, then $A{\\bf x}={\\bf b}$ does not have a unique solution.    If on the other hand $A$ is not singular, but has a very large condition number, then solving $A{\\bf x}={\\bf b}$ can be very inaccurate.   A small change in ${\\bf b}$ (such as might be introduced by limited precision in your computer) will result in a huge change to the solution, ${\\bf x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 87
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Demonstration.__\n",
    "\n",
    "Here is a demonstration of why this is a problem.\n",
    "\n",
    "Here is a matrix that is singular:\n",
    "\n",
    "$$M = \\left[\\begin{array}{rr}1&2\\\\2&4\\end{array}\\right].$$\n",
    "\n",
    "You can see that it is singular because the second column is a multiple of the first column.\n",
    "\n",
    "Here is a matrix that is _almost_ singular:\n",
    "\n",
    "$$A = \\left[\\begin{array}{ll}1&2.0000000001\\\\2&4\\end{array}\\right].$$\n",
    "\n",
    "The second column is not a multiple of the first column, so technically this matrix is not singular.   But the second column is _almost_ a multiple of the first column.  \n",
    "\n",
    "Now let's solve $A{\\bf x} = {\\bf b}$ using matrix $A.$\n",
    "\n",
    "First, let's consider when ${\\bf b} = \\left[\\begin{array}{r}1\\\\2\\end{array}\\right].$\n",
    "\n",
    "Solving  $A{\\bf x} = \\left[\\begin{array}{r}1\\\\2\\end{array}\\right]$ we get ${\\bf x} = \\left[\\begin{array}{r}1\\\\0\\end{array}\\right].$\n",
    "\n",
    "Now, let's change ${\\bf b}$ just a little bit.  Let's set ${\\bf b} = \\left[\\begin{array}{l}1\\\\2.01\\end{array}\\right].$  \n",
    "\n",
    "Solving  $A{\\bf x} = \\left[\\begin{array}{l}1\\\\2.01\\end{array}\\right]$ we get ${\\bf x} = \\left[\\begin{array}{r}100000000\\\\-50000000\\end{array}\\right].$\n",
    "\n",
    "Notice how a small change in ${\\bf b}$ resulted in a huge change in ${\\bf x}.$  This is because the matrix $A$ has a large condition number.   In fact the condition number of $A$ is about 12,500,000,000.\n",
    "\n",
    "Now, this situation would not be a problem if you were always dealing with exact quantities in your computer.   But you are not.   Every floating point number has limited precision -- a limited number of digits that can be stored.   As a result, there can be a small error in the value of any number stored in the computer.    This is not normally a problem -- you would not typically notice it.   But if you are solving a system with a large condition number, the small error in ${\\bf b}$ can get expanded in a large error in ${\\bf x}$.  The error can be so large that the value you get for ${\\bf x}$ is wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 88,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To compute the condition number of a matrix `A` in `Python/numpy`, use `np.linalg.cond(A)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
